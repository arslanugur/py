
Chapter II - OVERVİEW OF STATISTICAL LEARNING

Quiz 2.1 - Introduction to Regression Models Quiz
In the expression Sales ≈ f(TV, Radio, Newspaper), "Sales" is the: Response
The variable which you are trying to model is called the response or outcome. 
The other variables are called features, predictors, or independent variables. 
Together, the collection of features and response values that you will use for fitting form your training data.

Quiz 2.2 - Dimensionality and Structured Models Quiz
A hypercube with side length 1 in d dimensions is defined to be the set of points (x1, x2, ..., xd) such that 0 <= x_j <= 1 for all j = 1, 2, ..., d. 
The boundary of the hypercube is defined to be the set of all points such that there exists a j for which 0 <= x_j <= 0.05 or 0.95 <= x_j <= 1 (namely, the boundary is the set of all points that have at least one dimension in the most extreme 10% of possible values). 
What proportion of the points in a hypercube of dimension 50 are in the boundary? 
(hint: you may want to calculate the volume of the non-boundary region)
Please give your answer as a value between 0 and 1 with 3 significant digits. If you think the answer is 50.52%, you should say 0.505:
The volume of the interior of the hypercube is 0.950 = 0.005. Thus, the volume of the boundary is 1-0.005 = 0.995.

Quiz 2.3 - Model Selection and Bias-Variance Tradeoff Quiz
A fitted model with more predictors will necessarily have a lower Training Set Error than a model with fewer predictors. :False

Quiz 2.3 - Model Selection and Bias-Variance Tradeoff Quiz
While doing a homework assignment, you fit a Linear Model to your data set. You are thinking about changing the Linear Model to a Quadratic one. Which of the following is most likely true: Using the Quadratic Model will decrease the Bias of your model.

Quiz 2.4 - Classification Quiz
Look at the graph given on page 30 of the Chapter 2 lecture slides. 
Which of the following is most likely true of what would happen to the Test Error curve as we move 1/K further above 1?
It does not make sense to have 1/K > 1

 - Introduction to R Quiz
You are doing an analysis in R and need to use the 'summary()' function, but you are not exactly sure how it works. Which of the following commands should you run? (There is more than one correct answer, so any one these will earn the point).
?summary(), ?summary, help(summary)
Make sure you always read the documentation so you know what functions do when you use them!

 - Chapter 2 Quiz
For each of the following parts, indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible model.
The sample size n is extremely large, and the number of predictors p is small:        Flexible is better
A flexible model will allow us to take full advantage of our large sample size.

The number of predictors p is extremely large, and the sample size n is small:        Flexible is worse
The flexible model will cause overfitting due to our small sample size.

The relationship between the predictors and response is highly non-linear:            Flexible is better
A flexible model will be necessary to find the nonlinear effect.

The variance of the error terms, i.e. sigma^2 = Var(\epsilon), is extremely high:     Flexible is worse
A flexible model will cause us to fit too much of the noise in the problem.

########################################################################################################################

CHAPTER III - LINEAR REGRESSION

 - Simple Linear Regression Quiz
Linear regression important to understand: Linear regression is very extensible and can be used to capture nonlinear effects
Simple methods can outperform more complex ones if the data are noisy
Understanding simpler methods sheds light on more complex ones
The linear model (and every other model) is hardly ever true, but it is an important piece in many more complex methods.

You may want to reread the paragraph on confidence intervals on page 66 of the textbook before trying this queston (the distinctions are subtle). Which of the following are true statements? 
A 95% confidence interval is a random interval that contains the true parameter 95% of the time
The true parameter (unknown to me) is 0.5. If I sample data and construct a 95% confidence interval, the interval will contain 0.5 95% of the time.
Confidence intervals are a "frequentist" concept: the interval, and not the true parameter, is considered random.

 - Hyphotesis Testing and Confidence Invervals Quiz
We run a linear regression and the slope estimate is 0.5 with estimated standard error of 0.2. What is the largest value of b for which we would NOT reject the null hypothesis that β_1=b? (assume normal approximation to t distribution, and that we are using the 5% significance level for a two-sided test; need two significant digits of accuracy)     ----->   0.892
The 95% confidence interval β^_1 ± 1.96 S.E.(β^_1) contains all parameter values that would not be rejected at a 5% significance level.

Which of the following indicates a fairly strong relationship between X and Y?  ------>  R^2 = 0.9
The R2 is the correlation between the two variables and measures how closely they are associated. The p value and t statistic merely measure how strong is the evidence that there is a nonzero association. Even a weak effect can be extremely significant given enough data.

 - Multiple Linear Regression
Suppose we are interested in learning about a relationship between X_1 and Y, which we would ideally like to interpret as causal.
The estimate \hat\beta_1 in a linear regression that controls for many variables (that is, a regression with many predictors in addition to X_1) is usually a more reliable measure of a causal relationship than \hat\beta_1 from a univariate regression on X_1.
False
Adding lots of extra predictors to the model can just as easily muddy the interpretation of β^1 as it can clarify it. One often reads in media reports of academic studies that "the investigators controlled for confounding variables," but be skeptical!
Causal inference is a difficult and slippery topic, which cannot be answered with observational data alone without additional assumptions.


 - Some important questions
According to the balance vs ethnicity model, what's the predicted balance for an Asian in the data set? (within 0.01 accuracy)
-----> 512.31 
For an Asian, the predicted balance is the intercept plus the Asian ethnicity effect


What is the predicted balance for an African American? (within .01 accuracy) ----> 531
For an African American, the predicted balance is just the intercept.
Note that despite the differing predictions, this difference is not statistically significant.

 - Extensions of the linear model
According to the model for sales vs TV interacted with radio, what is the effect of an additional $1 of radio advertising if TV=$50? (with 4 decimal accuracy)   -----> .0839

What if TV=$250? (with 4 decimal accuracy) ----> .3039
The effect of an additional unit of radio is .0289 plus .0011 times TV.

 - Linear Regression in R
What is the difference between lm(y ~ xz) and lm(y ~ I(xz)), when x and z are both numeric variables?
The second includes only an interaction term for x and z, while the first includes both interaction effects and main effects.
An interaction term between a numeric x and z is just the product of x and z. The difference is that in the first model, lm processes the "*" operator between variables and automatically includes main effects, whereas in the latter model, the expression inside the I() function is not parsed as a part of the formula, but rather is simply evaluated.

 - Chapter 3 Quiz
Which of the following statements are true?
In the balance vs. income * student model plotted on slide 44, the estimate of beta3 is negative.
We can see that the estimate of beta3 is negative because the slope of the student line is smaller than the slope of the non-student line. That is, being a student diminishes the effect of income on balance.
The linear model is almost always wrong; however, it is often still useful.
The F statistic tests the null hypothesis that none of the predictors has any effect. Rejecting that null means concluding that *some* predictor has an effect, not that *all* of them do.
Positive correlation only means that the univariate regression has a positive correlation. See slide 20 for a counterexample.

########################################################################################################################

CHAPTER IV - CLASSIFICATION








