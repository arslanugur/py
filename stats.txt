
Chapter II - OVERVİEW OF STATISTICAL LEARNING

Quiz 2.1 - Introduction to Regression Models Quiz
In the expression Sales ≈ f(TV, Radio, Newspaper), "Sales" is the: Response
The variable which you are trying to model is called the response or outcome. 
The other variables are called features, predictors, or independent variables. 
Together, the collection of features and response values that you will use for fitting form your training data.

Quiz 2.2 - Dimensionality and Structured Models Quiz
A hypercube with side length 1 in d dimensions is defined to be the set of points (x1, x2, ..., xd) such that 0 <= x_j <= 1 for all j = 1, 2, ..., d. 
The boundary of the hypercube is defined to be the set of all points such that there exists a j for which 0 <= x_j <= 0.05 or 0.95 <= x_j <= 1 (namely, the boundary is the set of all points that have at least one dimension in the most extreme 10% of possible values). 
What proportion of the points in a hypercube of dimension 50 are in the boundary? 
(hint: you may want to calculate the volume of the non-boundary region)
Please give your answer as a value between 0 and 1 with 3 significant digits. If you think the answer is 50.52%, you should say 0.505:
The volume of the interior of the hypercube is 0.950 = 0.005. Thus, the volume of the boundary is 1-0.005 = 0.995.

Quiz 2.3 - Model Selection and Bias-Variance Tradeoff Quiz
A fitted model with more predictors will necessarily have a lower Training Set Error than a model with fewer predictors. :False

Quiz 2.3 - Model Selection and Bias-Variance Tradeoff Quiz
While doing a homework assignment, you fit a Linear Model to your data set. You are thinking about changing the Linear Model to a Quadratic one. Which of the following is most likely true: Using the Quadratic Model will decrease the Bias of your model.

Quiz 2.4 - Classification Quiz
Look at the graph given on page 30 of the Chapter 2 lecture slides. 
Which of the following is most likely true of what would happen to the Test Error curve as we move 1/K further above 1?
It does not make sense to have 1/K > 1

 - Introduction to R Quiz
You are doing an analysis in R and need to use the 'summary()' function, but you are not exactly sure how it works. Which of the following commands should you run? (There is more than one correct answer, so any one these will earn the point).
?summary(), ?summary, help(summary)
Make sure you always read the documentation so you know what functions do when you use them!

 - Chapter 2 Quiz
For each of the following parts, indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible model.
The sample size n is extremely large, and the number of predictors p is small:        Flexible is better
A flexible model will allow us to take full advantage of our large sample size.

The number of predictors p is extremely large, and the sample size n is small:        Flexible is worse
The flexible model will cause overfitting due to our small sample size.

The relationship between the predictors and response is highly non-linear:            Flexible is better
A flexible model will be necessary to find the nonlinear effect.

The variance of the error terms, i.e. sigma^2 = Var(\epsilon), is extremely high:     Flexible is worse
A flexible model will cause us to fit too much of the noise in the problem.

########################################################################################################################

CHAPTER III - LINEAR REGRESSION

 - Simple Linear Regression Quiz
Linear regression important to understand: Linear regression is very extensible and can be used to capture nonlinear effects
Simple methods can outperform more complex ones if the data are noisy
Understanding simpler methods sheds light on more complex ones
The linear model (and every other model) is hardly ever true, but it is an important piece in many more complex methods.

You may want to reread the paragraph on confidence intervals on page 66 of the textbook before trying this queston (the distinctions are subtle). Which of the following are true statements? 
A 95% confidence interval is a random interval that contains the true parameter 95% of the time
The true parameter (unknown to me) is 0.5. If I sample data and construct a 95% confidence interval, the interval will contain 0.5 95% of the time.
Confidence intervals are a "frequentist" concept: the interval, and not the true parameter, is considered random.

 - Hyphotesis Testing and Confidence Invervals Quiz
We run a linear regression and the slope estimate is 0.5 with estimated standard error of 0.2. What is the largest value of b for which we would NOT reject the null hypothesis that β_1=b? (assume normal approximation to t distribution, and that we are using the 5% significance level for a two-sided test; need two significant digits of accuracy)     ----->   0.892
The 95% confidence interval β^_1 ± 1.96 S.E.(β^_1) contains all parameter values that would not be rejected at a 5% significance level.

Which of the following indicates a fairly strong relationship between X and Y?  ------>  R^2 = 0.9
The R2 is the correlation between the two variables and measures how closely they are associated. The p value and t statistic merely measure how strong is the evidence that there is a nonzero association. Even a weak effect can be extremely significant given enough data.

 - Multiple Linear Regression
Suppose we are interested in learning about a relationship between X_1 and Y, which we would ideally like to interpret as causal.
The estimate \hat\beta_1 in a linear regression that controls for many variables (that is, a regression with many predictors in addition to X_1) is usually a more reliable measure of a causal relationship than \hat\beta_1 from a univariate regression on X_1.
False
Adding lots of extra predictors to the model can just as easily muddy the interpretation of β^1 as it can clarify it. One often reads in media reports of academic studies that "the investigators controlled for confounding variables," but be skeptical!
Causal inference is a difficult and slippery topic, which cannot be answered with observational data alone without additional assumptions.


 - Some important questions
According to the balance vs ethnicity model, what's the predicted balance for an Asian in the data set? (within 0.01 accuracy)
-----> 512.31 
For an Asian, the predicted balance is the intercept plus the Asian ethnicity effect


What is the predicted balance for an African American? (within .01 accuracy) ----> 531
For an African American, the predicted balance is just the intercept.
Note that despite the differing predictions, this difference is not statistically significant.

 - Extensions of the linear model
According to the model for sales vs TV interacted with radio, what is the effect of an additional $1 of radio advertising if TV=$50? (with 4 decimal accuracy)   -----> .0839

What if TV=$250? (with 4 decimal accuracy) ----> .3039
The effect of an additional unit of radio is .0289 plus .0011 times TV.

 - Linear Regression in R
What is the difference between lm(y ~ xz) and lm(y ~ I(xz)), when x and z are both numeric variables?
The second includes only an interaction term for x and z, while the first includes both interaction effects and main effects.
An interaction term between a numeric x and z is just the product of x and z. The difference is that in the first model, lm processes the "*" operator between variables and automatically includes main effects, whereas in the latter model, the expression inside the I() function is not parsed as a part of the formula, but rather is simply evaluated.

 - Chapter 3 Quiz
Which of the following statements are true?
In the balance vs. income * student model plotted on slide 44, the estimate of beta3 is negative.
We can see that the estimate of beta3 is negative because the slope of the student line is smaller than the slope of the non-student line. That is, being a student diminishes the effect of income on balance.
The linear model is almost always wrong; however, it is often still useful.
The F statistic tests the null hypothesis that none of the predictors has any effect. Rejecting that null means concluding that *some* predictor has an effect, not that *all* of them do.
Positive correlation only means that the univariate regression has a positive correlation. See slide 20 for a counterexample.

########################################################################################################################

CHAPTER IV - CLASSIFICATION

 - Introduction to Classification Problem Quiz
Which of the following is the best example of a Qualitative Variable?
Colors are discrete values with no clear ordering. Height, Age, and Speed are all continuous.

Judging from the plots on page 2 of the notes, which should be the better predictor of Default: Income or Balance?
Income.     (Balance.)    Both are equally good.     Not enough information is given to decide.
Default is clearly associated with higher balances. On the other hand, the rate of default seems fairly constant across income levels.

 - Logistic Regression Quiz
Using the model on page 8 of the notes, what value of Balance will give a predicted Default rate of 50%? (within 3 units of accuracy)
Enter the value of Balance below:   -----> 1936.6
We know that logit(.5) = β_0+β_1*Balance. Thus, Balance = (logit(.5) - β-0)/β_1 = (log(.5/(1-.5)) + 10.6513)/.0055 = 1936.6

 - Multivariate Logistic Regression Quiz
Suppose we collect data for a group of students in a statistics class with variables X_1 hours studied, X_2 undergrad GPA, and Y= receive an A. We fit a logistic regression and produce estimated coefficients \hat\beta_o = -6, \hat\beta_1 = 0.05, \hat\beta_2 = 1.
Estimate the probability that a student who studies for 40h and has an undergrad GPA of 3.5 gets an A in the class (within 0.01 accuracy):
-----> 0.3775
We know that P((40,3.5)) = e−6+.05∗40+1∗3.51+e−6+.05∗40+1∗3.5 = .37554

How many hours would that student need to study to have a 50% chance of getting an A in the class?:  50
We have P((h,3.5)) = e−6+.05∗h+1∗3.51+e−6+.05∗h+1∗3.5 = .5. Rearranging gives −6+.05∗h+1∗3.5 = 0 or h = 50

 - Logistic Regression - Case-Control Sampling and Multiclass Quiz
In which of the following problems is Case/Control Sampling LEAST likely to make a positive impact?
Predicting a shopper's gender based on the products they buy
Case/Control sampling is most effective when the prior probabilities of the classes are very unequal. We expect this to be the case for the cancer and spam problems, but not the gender problem.

 - Discriminant Analysis Quiz
Suppose that in Ad Clicks (a problem where you try to model if a user will click on a particular ad) it is well known that the majority of the time an ad is shown it will not be clicked. What is another way of saying that?
Ad Clicks have a low Prior Probability
Whether or not an ad gets clicked is a Qualitative Variable. Thus, it does not have a density. The Prior Probability of Ad Clicks is low because most ads are not clicked.

 - Gaussian Discriminant Analysis - One Variable Quiz
Which of the following is NOT a linear function in x:
f(x) = a + b^2x
The discriminant function from LDA
\delta_k(x) = x\frac{\mu_k}{\sigma^2} - \frac{\mu_k^2}{2\sigma^2} +\log(\pi_k)
\text{logit}(P(y = 1 | x)) where P(y=1 | x) is as in logistic regression
----> P(y=1 | x) from logistic regression
P(y=1|x)  from logistic regression is not linear because it involves both an exponential function of x and a ratio. Notice that f(x)=a+b^2x is not a linear function of b, but is a linear function of x.

 - Gaussian Discriminant Analysis - Many Variables
Why does Total Error keep going down on the graph on page 34 of the notes, even though the False Negative Rate increases?
---> Positive responses are so uncommon that their impact on the Total Error is small.
The Total Error is a weighted average of the False Positive Rate and False Negative Rate. The weights are determined by the Prior Probabilities of Positive and Negative Responses. Although the False Negative Rate might be high, the prior for positive responses is very small.

 - Quadratic Discriminant Analysis and Naive Bayes Quiz
Which of the following statements best explains the relationship between Quadratic Discriminant Analysis and naive Bayes with Gaussian distributions in each class?
----> Quadratic Discriminant Analysis is a more flexible class of models than naive Bayes
With Gaussian distributions, naive Bayes is equivalent to Quadratic Discriminant Analysis with the additional requirement that each class covariance matrix Σ_k be diagonal. Thus, Quadratic Discriminant Analysis is more flexible.

 - Classification in R
In ch4.R, line 13 is "attach(Smarket)." If that line was omitted from the script, which of the following lines would cause an error?:
-----> line 15: mean(glm.pred==Direction)
attach() allows a user to access the columns of a data.frame directly. In this case, line 15 uses "Direction" instead of "Smarket$Direction".

 - Chapter 4 Quiz
Which of the following tools would be well suited for predicting if a student will get an A in a class based on the student's height, and parents’ income? Select all that apply:
-----> Linear Discriminant Analysis
-----> Linear Regression
----> Logistic Regression
Whether or not a student gets an A is a categorical variables. Thus, we should use a classification technique like LDA or Logistic Regression. For binary classification, linear regression and LDA are almost equivalent.


########################################################################################################################

CHAPTER V - RESAMPLING

 - d





